# **`@sap/llm-commons`** JS/TS library

A Commons JavaScript/TypeScript Library for building Generative AI applications on SAP BTP.

> ‚ö†Ô∏è **Warning**
>
> This library is under active development and does not yet have a major release. Please expect this library might introduce features in a backward-incompatible fashion, though we strive not to.

- [**`@sap/llm-commons`** JS/TS library](#sapllm-commons-jsts-library)
  - [üìö Documentation](#-documentation)
  - [üöÄ Get Started](#-get-started)
    - [üéπ About Harmonized BTP LLM Client](#-about-harmonized-btp-llm-client)
    - [üí° Usage: ‚ú® LLM Client](#-usage--llm-client)
    - [üí° Usage: ü¶úüîó LangChain](#-usage--langchain)
      - [1. ü¶úüîó LangChain: LLM Model](#1--langchain-llm-model)
      - [2. ü¶úüîó LangChain: Chat Model](#2--langchain-chat-model)
      - [3. ü¶úüîó LangChain: Embedding Model](#3--langchain-embedding-model)
  - [‚úîÔ∏è Models Support](#Ô∏è-models-support)
    - [‚ú® BTP LLM Clients](#-btp-llm-clients)
    - [ü¶úüîó LangChain](#-langchain)
      - [1. üêç LLM](#1--llm)
      - [2. üí¨ Chat](#2--chat)
      - [3. üß† Embedding](#3--embedding)
  - [ü§ù Contribute](#-contribute)
  - [üôå Support and Contact](#-support-and-contact)

## üìö Documentation

- [API Docs](./docs/api/)
- [Examples - various usecases](./examples)
- [Development & Internal Docs](./docs/)

## üöÄ Get Started

You can easily consume this libary in your JS/TS projects by following the below steps

1. Create `.npmrc` at the root of the project with below registry url

```properties
registry=https://int.repositories.cloud.sap/artifactory/api/npm/build-releases-npm
```

2. Install the packages

```sh
# install BTP LLM Commons
npm install @sap/llm-commons

# install langchain (Required if using LangChain framework)
npm install langchain
```

3. (For Local) Once you have credentials for **BTP LLM Proxy Service** (see [docs](https://github.tools.sap/I057149/azure-openai-service/)), you can follow one of the steps below

   - Create a file under your home directory - `~/.btp_llm/config.json` with following content

   ```jsonc
   {
     "BTP_LLM_CLIENT_ID": "<CLIENT_ID>",
     "BTP_LLM_CLIENT_SECRET": "<CLIENT_SECRET>",
     "BTP_LLM_AUTH_URL": "<AUTH_URL>", // the Auth URL ending `ondemand.com`
     "BTP_LLM_API_BASE": "<BASE_URL>" //
   }
   ```

   - Export the secrets as environment variables

   ```bash
   export BTP_LLM_CLIENT_ID=<CLIENT_ID>
   export BTP_LLM_CLIENT_SECRET=<CLIENT_SECRET>
   export BTP_LLM_AUTH_URL=<AUTH_URL> # the Auth URL ending `ondemand.com`
   export BTP_LLM_API_BASE=<BASE_URL> # the service URL ending `ondemand.com`
   ```

   - While initialize the context, you can pass in the secrets too

   ```typescript
   import { BTPLLMContext } from "@sap/llm-commons";

   // initialize context once at the start of the app/server
   await BTPLLMContext.init({
     oauthClientId: "<CLIENT_ID>",
     oauthClientSecret: "<CLIENT_SECRET>",
     oauthTokenUrl: "<AUTH_URL>", // the Auth URL ending `ondemand.com`
     llmProxyBaseUrl: "<BASE_URL>", // the service URL ending `ondemand.com`
   });
   ```

4. (For Cloud) The **BTP LLM Proxy Service** must be bound to your application (see [docs](https://github.tools.sap/I057149/azure-openai-service/#to-use-this-service-in-your-application-follow-these-steps)) and this library automatically can read from `VCAP_SERVICES` environment variable.

5. Initialize the BTP LLM Context at the start of the app/server

```typescript
import { BTPLLMContext } from "@sap/llm-commons";

// initialize context once at the start of the app/server
await BTPLLMContext.init();
```

5. Then proceed below to either use the [LLM Client](#usage-llm-client) or via [LangChain](#usage-langchain)

### üéπ About Harmonized BTP LLM Client

A harmonized BTP LLM Client interface is available for all Text, Chat & Embedding models. This is much similar to Python's version of [Harmonized Model Initialization](https://github.tools.sap/AI-Playground-Projects/llm-commons#harmonized-model-initialization) - `init_llm` & `init_embedding_model` but uses _class_ styled client initialisation. See '_Harmonized_ BTP LLM Proxy Client' usage in respective sections below.

- Harmonized input & output interface with parameter normalisation for all LLMs with often used parameters
- Supports Text-completion & Chat-completion (both supported for all text & chat models) and Embedding for supported models
- For Anthropic, LLaMa 2 models, the chat interface is created by correctly wrapping with special tokens as mentioned by the respective docs.
- The parameters and interfaces are designed based on OpenAI's GPT models
- With LangChain, [OpenAI Functions Agent](https://js.langchain.com/docs/modules/agents/agent_types/openai_functions_agent) support (when used with GPT-3.5 & GPT-4 models, which can also work with other LLMs if they get support)
- Sometimes, it may not be apt to use the harmonized client since each LLM has certain strengths such as
  - for few-shot prompting with `examples` parameter in case of `gcp-chat-bison-001`
  - try out advanced parameters for each LLM especially for that of `alephalpha` which contains so many tweakable parameters.

### üí° Usage: ‚ú® LLM Client

<details>
  <summary>1. Harmonized BTP LLM Proxy Client</summary>

1. Initialize the LLM Client

```typescript
import { BTPLLMProxyClient } from "@sap/llm-commons/client/btp";

const btpLLMProxy = new BTPLLMProxyClient();
```

2.  Use the client for generating text, chat completion or embedding

```typescript
/// Harmonized BTP LLM Proxy Text Completion ///
// you may use any text or chat model for text completion
const resText = await btpLLMProxy.createTextCompletion({
  deployment_id: "gpt-35-turbo",
  prompt: "What would be a good company name for a company that makes colorful socks?",
});

// Chat Completion //
/// Harmonized BTP LLM Proxy Chat Completion ///
// you may use any text or chat model for chat completion
const resChat = await btpLLMProxy.createChatCompletion({
  deployment_id: "llama2-70b-chat-hf",
  messages: [
    {
      content: "You are a consultant who name things creatively in Pirate's language",
      role: "system",
    },
    {
      content: "What would be a good company name for a company that makes colorful socks?",
      role: "user",
    },
  ],
});

// Embedding //
const resEmbedding = await btpLLMProxy.createEmbedding({
  deployment_id: "text-embedding-ada-002-v2",
  input: "SAP SE is a German multinational software company",
});
```

</details>

<details>
  <summary>2. OpenAI</summary>

1. Initialize the LLM Client

```typescript
import { BTPOpenAIClient } from "@sap/llm-commons/client/openai";

const openai = new BTPOpenAIClient();
```

2.  Use the client for generating text, chat completion or embedding

```typescript
// Text Completion //
const res = await openai.createCompletion({
  deployment_id: "text-davinci-003",
  prompt: "once upon a time",
});

// Chat Completion //
const res = await openai.createChatCompletion({
  deployment_id: "gpt-35-turbo",
  messages: [
    {
      content: "You are a story teller and start narrating a story",
      role: "system",
    },
    {
      content: "once upon a time",
      role: "user",
    },
  ],
});

// Embedding //
const res = await openai.createEmbedding({
  deployment_id: "text-embedding-ada-002-v2",
  input: "SAP SE is a German multinational software company",
});
```

</details>

<details>
  <summary>3. Google PaLM</summary>

1. Initialize the LLM Client

```typescript
import { BTPGooglePaLMClient } from "@sap/llm-commons/client/google";

const googlePaLM = new BTPGooglePaLMClient();
```

2.  Use the client for generating text, chat completion or embedding

```typescript
// Text Completion //
const resText = await googlePaLM.predictText({
  deployment_id: "gcp-text-bison-001",
  instances: [
    {
      prompt: "once upon a time",
    },
  ],
  parameters: {
    maxOutputTokens: 100,
  },
});

// Chat Completion //
const resChat = await googlePaLM.predictChat({
  deployment_id: "gcp-chat-bison-001",
  instances: [
    {
      messages: [
        {
          content: "What would be a good company name for a company that makes colorful socks?",
          author: "user",
        },
      ],
    },
  ],
  parameters: {
    maxOutputTokens: 1024,
  },
});

// Embedding //
const resEmbedding = await googlePaLM.embedText({
  deployment_id: "gcp-textembedding-gecko-001",
  instances: [
    {
      content: "SAP SE is a German multinational software company",
    },
  ],
});
```

</details>

<details>
  <summary>4. Anthropic Claude</summary>

1. Initialize the LLM Client

```typescript
import { BTPAnthropicClaudeClient } from "@sap/llm-commons/client/anthropic";

const anthropicClaude = new BTPAnthropicClaudeClient();
```

> ‚ÑπÔ∏è Info
>
> Though the Anthropic Claude model provides only a text `prompt` input, BTP Anthropic Claude client provides a chat wrapper by correctly formatting the input prompt, by surrounding with special tokens `\n\nHuman:` and `\n\nAssistant:` as mentioned in Anthropic [docs](https://docs.anthropic.com/claude/docs/constructing-a-prompt#use-the-correct-format)

2.  Use the client for generating chat completion

```typescript
// Chat Completion //
const resChat = await anthropicClaude.createChatCompletion({
  deployment_id: "anthropic-claude-v2",
  messages: [
    {
      role: "Human",
      content:
        "You are a consultant who name things creatively in Pirate's language. What would be a good company name for a company that makes colorful socks?",
    },
  ],
  max_tokens_to_sample: 100,
  temperature: 1, // optional
  top_k: 40, // optional
  top_p: 1, // optional
});
```

</details>

<details>
  <summary>5. Cohere Command</summary>

1. Initialize the LLM Client

```typescript
import { BTPCohereCommandClient } from "@sap/llm-commons/client/cohere";

const cohereCommand = new BTPCohereCommandClient();
```

1.  Use the client for generating text completion

```typescript
// Text Completion //
const resText = await cohereCommand.createTextCompletion({
  deployment_id: "cohere-command",
  prompt: "Who is the captain of Black Pearl?",
  temperature: 0, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>6. Amazon Titan</summary>

1. Initialize the LLM Client

```typescript
import { BTPAmazonTitanClient } from "@sap/llm-commons/client/amazon";

const amazonTitan = new BTPAmazonTitanClient();
```

2.  Use the client for generating text completion or embedding

```typescript
// Text Completion //
const resText = await amazonTitan.createTextCompletion({
  deployment_id: "amazon-titan-tg1-large",
  inputText: "once upon a time ",
  textGenerationConfig: {
    // optional
    maxTokenCount: 100, // optional
    temperature: 0.8, // optional
    topP: 0.7, // optional
  },
});

// Embedding //
const resEmbedding = await amazonTitan.createEmbedding({
  deployment_id: "amazon-titan-e1t-medium",
  inputText: "SAP SE is a German multinational software company",
});
```

</details>

<details>
  <summary>7. AlephAlpha Luminous</summary>

1. Initialize the LLM Client

```typescript
import { BTPAlephAlphaLuminousClient } from "@sap/llm-commons/client/alephalpha";

const alephalphaLuminous = new BTPAlephAlphaLuminousClient();
```

1.  Use the client for generating text completion

```typescript
// Text Completion //
const resText = await alephalphaLuminous.createTextCompletion({
  deployment_id: "alephalpha",
  prompt: "Who is the captain of Black Pearl? ",
  maximum_tokens: 100,
  temperature: 0, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>8. AI21 Jurassic</summary>

1. Initialize the LLM Client

```typescript
import { BTPAI21JurassicClient } from "@sap/llm-commons/client/ai21";

const ai21Jurassic = new BTPAI21JurassicClient();
```

1.  Use the client for generating text completion

```typescript
// Text Completion //
const resText = await ai21Jurassic.createTextCompletion({
  deployment_id: "ai21-j2-grande-instruct",
  prompt: "Who is the captain of Black Pearl? ",
  temperature: 0, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>9. HuggingFace</summary>

1. Initialize the LLM Client

```typescript
import { BTPHuggingFaceClient } from "@sap/llm-commons/client/huggingface";

const huggingface = new BTPHuggingFaceClient();
```

1.  Use the client for generating text completion

```typescript
// Text Completion //
const resText = await huggingface.textGeneration({
  deployment_id: "llama2-70b-chat-hf",
  inputs: "Who is the captain of Black Pearl? ",
  parameters: {
    temperature: 1.0, // optional
    // other optional properties
  },
});
```

</details>

### üí° Usage: ü¶úüîó LangChain

#### 1. ü¶úüîó LangChain: LLM Model

1. Initialize the [LangChain LLM Model](https://js.langchain.com/docs/modules/model_io/models/llms/)

<details>
  <summary>1. Harmonized BTP LLM Proxy</summary>

```typescript
import { BTPLLMProxy } from "@sap/llm-commons/langchain/llm/btp";

const model = new BTPLLMProxy({
  deployment_id: "gcp-chat-bison-001", // you may use any chat or text model here
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>2. OpenAI</summary>

```typescript
import { BTPOpenAI } from "@sap/llm-commons/langchain/llm/openai";

const model = new BTPOpenAI({
  deployment_id: "text-davinci-003",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>3. Google PaLM</summary>

```typescript
import { BTPGooglePaLM } from "@sap/llm-commons/langchain/llm/google";

const model = new BTPGooglePaLM({
  deployment_id: "gcp-text-bison-001",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>4. Cohere Command</summary>

```typescript
import { BTPCohereCommand } from "@sap/llm-commons/langchain/llm/cohere";

const model = new BTPCohereCommand({
  deployment_id: "cohere-command",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>5. Amazon Titan</summary>

```typescript
import { BTPAmazonTitan } from "@sap/llm-commons/langchain/llm/amazon";

const model = new BTPAmazonTitan({
  deployment_id: "amazon-titan-tg1-large",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>6. AlephAlpha Luminous</summary>

```typescript
import { BTPAlephAlphaLuminous } from "@sap/llm-commons/langchain/llm/alephalpha";

const model = new BTPAlephAlphaLuminous({
  deployment_id: "alephalpha",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>7. AI21 Jurassic</summary>

```typescript
import { BTPAI21Jurassic } from "@sap/llm-commons/langchain/llm/ai21";

const model = new BTPAI21Jurassic({
  deployment_id: "ai21-j2-grande-instruct",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>8. Huggingface</summary>

```typescript
import { BTPHuggingFace } from "@sap/llm-commons/langchain/llm/huggingface";

const model = new BTPHuggingFace({
  deployment_id: "llama2-70b-chat-hf",
  temperature: 1.0, // optional
  maxTokens: 250, // optional
  // other optional properties
});
```

</details>

2.  Use the model further in LangChain's [Chains](https://js.langchain.com/docs/modules/chains/), [Agents](https://js.langchain.com/docs/modules/agents/) etc. or use standalone like below

```typescript
const res = await model.call("Question: What would be a good company name a company that makes colorful socks?\nAnswer:");
```

#### 2. ü¶úüîó LangChain: Chat Model

1. Initialize the [LangChain Chat Model](https://js.langchain.com/docs/modules/model_io/models/chat/)

<details>
  <summary>1. Harmonized BTP LLM Proxy</summary>

```typescript
import { BTPLLMProxyChat } from "@sap/llm-commons/langchain/chat/btp";

const model = new BTPLLMProxyChat({
  deployment_id: "anthropic-claude-v2", // you may use any chat or text model here
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>2. OpenAI</summary>

```typescript
import { BTPOpenAIChat } from "@sap/llm-commons/langchain/chat/openai";

const model = new BTPOpenAIChat({
  deployment_id: "gpt-4",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>3. Google PaLM</summary>

```typescript
import { BTPGooglePaLMChat } from "@sap/llm-commons/langchain/chat/google";

const model = new BTPGooglePaLMChat({
  deployment_id: "gcp-chat-bison-001",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

<details>
  <summary>4. Anthropic Claude</summary>

```typescript
import { BTPAnthropicClaudeChat } from "@sap/llm-commons/langchain/chat/anthropic";

const model = new BTPAnthropicClaudeChat({
  deployment_id: "anthropic-claude-v2",
  temperature: 0.7, // optional
  // other optional properties
});
```

</details>

2.  Use the model further in LangChain's [Chains](https://js.langchain.com/docs/modules/chains/), [Agents](https://js.langchain.com/docs/modules/agents/) etc. or use standalone like below

```typescript
import { HumanMessage, SystemMessage } from "langchain/schema";

const res2 = await model.call([
  new SystemMessage("You are a helpful assistant that translates English to French."),
  new HumanMessage("Translate: I love programming."),
]);
```

#### 3. ü¶úüîó LangChain: Embedding Model

1. Initialize the [LangChain Embedding Model](https://js.langchain.com/docs/modules/model_io/models/embeddings/)

<details>
  <summary>1. Harmonized BTP LLM Proxy</summary>

```typescript
import { BTPLLMProxyEmbedding } from "@sap/llm-commons/langchain/embedding/btp";

const model = new BTPLLMProxyEmbedding({
  deployment_id: "text-embedding-ada-002-v2",
});
```

</details>

<details>
  <summary>2. OpenAI</summary>

```typescript
import { BTPOpenAIEmbedding } from "@sap/llm-commons/langchain/embedding/openai";

const model = new BTPOpenAIEmbedding({
  deployment_id: "text-embedding-ada-002-v2",
});
```

</details>

<details>
  <summary>3. Google PaLM</summary>

```typescript
import { BTPGooglePaLMEmbedding } from "@sap/llm-commons/langchain/embedding/google";

const model = new BTPGooglePaLMEmbedding({
  deployment_id: "gcp-textembedding-gecko-001",
});
```

</details>

<details>
  <summary>4. Amazon Titan</summary>

```typescript
import { BTPAmazonTitanEmbedding } from "@sap/llm-commons/langchain/embedding/amazon";

const model = new BTPAmazonTitanEmbedding({
  deployment_id: "amazon-titan-e1t-medium",
});
```

</details>

2.  Use the model further in LangChain's [Chains](https://js.langchain.com/docs/modules/chains/), [Agents](https://js.langchain.com/docs/modules/agents/), [Memory](https://js.langchain.com/docs/modules/memory/) etc. or use standalone like below

```typescript
// embed single query
const res = await model.embedQuery("Hello world");

// embed multiple documents
const documentRes = await model.embedDocuments(["Hello world", "Bye bye"]);
```

## ‚úîÔ∏è Models Support

For more info on what models are available from BTP LLM Proxy, see [here](https://github.tools.sap/I057149/azure-openai-service/)

### ‚ú® BTP LLM Clients

|                         **Model Family**                         | **Type**  |       **Deployment ID**       |                                 **BTP LLM Client**                                 |
| :--------------------------------------------------------------: | :-------: | :---------------------------: | :--------------------------------------------------------------------------------: |
|          ![SAP BTP](./docs/images/icons/sap-32x32.jpg)           |   Text    |     _Any Text/Chat Model_     |         `import { BTPLLMProxyClient } from "@sap/llm-commons/client/btp"`          |
|          ![SAP BTP](./docs/images/icons/sap-32x32.jpg)           |   Chat    |     _Any Text/Chat Model_     |         `import { BTPLLMProxyClient } from "@sap/llm-commons/client/btp"`          |
|          ![SAP BTP](./docs/images/icons/sap-32x32.jpg)           | Embedding |     _Any Embedding Model_     |         `import { BTPLLMProxyClient } from "@sap/llm-commons/client/btp"`          |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |   Text    |      `text-davinci-003`       |         `import { BTPOpenAIClient } from "@sap/llm-commons/client/openai"`         |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |   Code    |      `code-davinci-002`       |         `import { BTPOpenAIClient } from "@sap/llm-commons/client/openai"`         |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |   Chat    |        `gpt-35-turbo`         |         `import { BTPOpenAIClient } from "@sap/llm-commons/client/openai"`         |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |   Chat    |      `gpt-35-turbo-16k`       |         `import { BTPOpenAIClient } from "@sap/llm-commons/client/openai"`         |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |   Chat    |            `gpt-4`            |         `import { BTPOpenAIClient } from "@sap/llm-commons/client/openai"`         |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |   Chat    |          `gpt-4-32k`          |         `import { BTPOpenAIClient } from "@sap/llm-commons/client/openai"`         |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          | Embedding |  `text-embedding-ada-002-v2`  |         `import { BTPOpenAIClient } from "@sap/llm-commons/client/openai"`         |
|     ![Google PaLM](./docs/images/icons/googlepalm-32x32.jpg)     |   Text    |     `gcp-text-bison-001`      |       `import { BTPGooglePaLMClient } from "@sap/llm-commons/client/google"`       |
|     ![Google PaLM](./docs/images/icons/googlepalm-32x32.jpg)     |   Chat    |     `gcp-chat-bison-001`      |       `import { BTPGooglePaLMClient } from "@sap/llm-commons/client/google"`       |
|     ![Google PaLM](./docs/images/icons/googlepalm-32x32.jpg)     | Embedding | `gcp-textembedding-gecko-001` |       `import { BTPGooglePaLMClient } from "@sap/llm-commons/client/google"`       |
|   ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg)   |   Chat    |     `anthropic-claude-v1`     |   `import { BTPAnthropicClaudeClient } from "@sap/llm-commons/client/anthropic"`   |
|   ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg)   |   Chat    |  `anthropic-claude-v1-100k`   |   `import { BTPAnthropicClaudeClient } from "@sap/llm-commons/client/anthropic"`   |
|   ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg)   |   Chat    | `anthropic-claude-instant-v1` |   `import { BTPAnthropicClaudeClient } from "@sap/llm-commons/client/anthropic"`   |
|   ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg)   |   Chat    |     `anthropic-claude-v2`     |   `import { BTPAnthropicClaudeClient } from "@sap/llm-commons/client/anthropic"`   |
|   ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg)   |   Chat    |  `anthropic-claude-v2-100k`   |   `import { BTPAnthropicClaudeClient } from "@sap/llm-commons/client/anthropic"`   |
|     ![Cohere Command](./docs/images/icons/cohere-32x32.jpg)      |   Text    |       `cohere-command`        |     `import { BTPCohereCommandClient } from "@sap/llm-commons/client/cohere"`      |
|        ![Amazon Titan](./docs/images/icons/aws-32x32.jpg)        |   Text    |   `amazon-titan-tg1-large`    |      `import { BTPAmazonTitanClient } from "@sap/llm-commons/client/amazon"`       |
|        ![Amazon Titan](./docs/images/icons/aws-32x32.jpg)        | Embedding |   `amazon-titan-e1t-medium`   |      `import { BTPAmazonTitanClient } from "@sap/llm-commons/client/amazon"`       |
| ![AlephAlpha Luminous](./docs/images/icons/alephalpha-32x32.jpg) |   Text    |         `alephalpha`          | `import { BTPAlephAlphaLuminousClient } from "@sap/llm-commons/client/alephalpha"` |
|       ![AI21 Jurassic](./docs/images/icons/ai21-32x32.jpg)       |   Text    |   `ai21-j2-grande-instruct`   |       `import { BTPAI21JurassicClient } from "@sap/llm-commons/client/ai21"`       |
|       ![AI21 Jurassic](./docs/images/icons/ai21-32x32.jpg)       |   Text    |   `ai21-j2-jumbo-instruct`    |       `import { BTPAI21JurassicClient } from "@sap/llm-commons/client/ai21"`       |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |   Text    |          `falcon-7b`          |    `import { BTPHuggingFaceClient } from "@sap/llm-commons/client/huggingface"`    |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |   Text    |     `falcon-40b-instruct`     |    `import { BTPHuggingFaceClient } from "@sap/llm-commons/client/huggingface"`    |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |   Text    |     `llama2-13b-chat-hf`      |    `import { BTPHuggingFaceClient } from "@sap/llm-commons/client/huggingface"`    |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |   Text    |     `llama2-70b-chat-hf`      |    `import { BTPHuggingFaceClient } from "@sap/llm-commons/client/huggingface"`    |

### ü¶úüîó LangChain

#### 1. üêç LLM

|                         **Model Family**                         |     **Deployment ID**     |                                  **LangChain** LLM                                  |
| :--------------------------------------------------------------: | :-----------------------: | :---------------------------------------------------------------------------------: |
|          ![SAP BTP](./docs/images/icons/sap-32x32.jpg)           |   _Any Text/Chat Model_   |         `import { BTPLLMProxy } from "@sap/llm-commons/langchain/llm/btp"`          |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |    `text-davinci-003`     |         `import { BTPOpenAI } from "@sap/llm-commons/langchain/llm/openai"`         |
|         ![OpenAI](./docs/images/icons/openai-32x32.png)          |    `code-davinci-002`     |         `import { BTPOpenAI } from "@sap/llm-commons/langchain/llm/openai"`         |
|     ![Google PaLM](./docs/images/icons/googlepalm-32x32.jpg)     |   `gcp-text-bison-001`    |       `import { BTPGooglePaLM } from "@sap/llm-commons/langchain/llm/google"`       |
|     ![Cohere Command](./docs/images/icons/cohere-32x32.jpg)      |     `cohere-command`      |     `import { BTPCohereCommand } from "@sap/llm-commons/langchain/llm/cohere"`      |
|        ![Amazon Titan](./docs/images/icons/aws-32x32.jpg)        | `amazon-titan-tg1-large`  |      `import { BTPAmazonTitan } from "@sap/llm-commons/langchain/llm/amazon"`       |
| ![AlephAlpha Luminous](./docs/images/icons/alephalpha-32x32.jpg) |       `alephalpha`        | `import { BTPAlephAlphaLuminous } from "@sap/llm-commons/langchain/llm/alephalpha"` |
|       ![AI21 Jurassic](./docs/images/icons/ai21-32x32.jpg)       | `ai21-j2-grande-instruct` |       `import { BTPAI21Jurassic } from "@sap/llm-commons/langchain/llm/ai21"`       |
|       ![AI21 Jurassic](./docs/images/icons/ai21-32x32.jpg)       | `ai21-j2-jumbo-instruct`  |       `import { BTPAI21Jurassic } from "@sap/llm-commons/langchain/llm/ai21"`       |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |        `falcon-7b`        |    `import { BTPHuggingFace } from "@sap/llm-commons/langchain/llm/huggingface"`    |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |   `falcon-40b-instruct`   |    `import { BTPHuggingFace } from "@sap/llm-commons/langchain/llm/huggingface"`    |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |   `llama2-13b-chat-hf`    |    `import { BTPHuggingFace } from "@sap/llm-commons/langchain/llm/huggingface"`    |
|    ![HuggingFace](./docs/images/icons/huggingface-32x32.jpg)     |   `llama2-70b-chat-hf`    |    `import { BTPHuggingFace } from "@sap/llm-commons/langchain/llm/huggingface"`    |

#### 2. üí¨ Chat

|                       **Model Family**                       |       **Deployment ID**       |                                  **LangChain** Chat                                  |
| :----------------------------------------------------------: | :---------------------------: | :----------------------------------------------------------------------------------: |
|        ![SAP BTP](./docs/images/icons/sap-32x32.jpg)         |     _Any Text/Chat Model_     |       `import { BTPLLMProxyChat } from "@sap/llm-commons/langchain/chat/btp"`        |
|       ![OpenAI](./docs/images/icons/openai-32x32.png)        |        `gpt-35-turbo`         |       `import { BTPOpenAIChat } from "@sap/llm-commons/langchain/chat/openai"`       |
|       ![OpenAI](./docs/images/icons/openai-32x32.png)        |      `gpt-35-turbo-16k`       |       `import { BTPOpenAIChat } from "@sap/llm-commons/langchain/chat/openai"`       |
|       ![OpenAI](./docs/images/icons/openai-32x32.png)        |            `gpt-4`            |       `import { BTPOpenAIChat } from "@sap/llm-commons/langchain/chat/openai"`       |
|       ![OpenAI](./docs/images/icons/openai-32x32.png)        |          `gpt-4-32k`          |       `import { BTPOpenAIChat } from "@sap/llm-commons/langchain/chat/openai"`       |
|   ![Google PaLM](./docs/images/icons/googlepalm-32x32.jpg)   |     `gcp-chat-bison-001`      |     `import { BTPGooglePaLMChat } from "@sap/llm-commons/langchain/chat/google"`     |
| ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg) |     `anthropic-claude-v1`     | `import { BTPAnthropicClaudeChat } from "@sap/llm-commons/langchain/chat/anthropic"` |
| ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg) |  `anthropic-claude-v1-100k`   | `import { BTPAnthropicClaudeChat } from "@sap/llm-commons/langchain/chat/anthropic"` |
| ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg) | `anthropic-claude-instant-v1` | `import { BTPAnthropicClaudeChat } from "@sap/llm-commons/langchain/chat/anthropic"` |
| ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg) |     `anthropic-claude-v2`     | `import { BTPAnthropicClaudeChat } from "@sap/llm-commons/langchain/chat/anthropic"` |
| ![Anthropic Claude](./docs/images/icons/anthropic-32x32.jpg) |  `anthropic-claude-v2-100k`   | `import { BTPAnthropicClaudeChat } from "@sap/llm-commons/langchain/chat/anthropic"` |

#### 3. üß† Embedding

|                     **Model Family**                     |       **Deployment ID**       |                                 **LangChain** Embedding                                 |
| :------------------------------------------------------: | :---------------------------: | :-------------------------------------------------------------------------------------: |
|      ![SAP BTP](./docs/images/icons/sap-32x32.jpg)       |     _Any Embedding Model_     |    `import { BTPLLMProxyEmbedding } from "@sap/llm-commons/langchain/embedding/btp"`    |
|     ![OpenAI](./docs/images/icons/openai-32x32.png)      |  `text-embedding-ada-002-v2`  |   `import { BTPOpenAIEmbedding } from "@sap/llm-commons/langchain/embedding/openai"`    |
| ![Google PaLM](./docs/images/icons/googlepalm-32x32.jpg) | `gcp-textembedding-gecko-001` | `import { BTPGooglePaLMEmbedding } from "@sap/llm-commons/langchain/embedding/google"`  |
|    ![Amazon Titan](./docs/images/icons/aws-32x32.jpg)    |   `amazon-titan-e1t-medium`   | `import { BTPAmazonTitanEmbedding } from "@sap/llm-commons/langchain/embedding/amazon"` |

## ü§ù Contribute

This project is [InnerSource](https://go.sap.corp/innersource) - contributions are welcome!
If you're interested please check these two important documents:

- [CONTRIBUTING.md](CONTRIBUTING.md) contains operational details on how to contribute. If you are new to this project and want to contribute, please start here.
- [GOVERNANCE.md](GOVERNANCE.md) documents how the project is run and explains how to engage with the community.

## üôå Support and Contact

If you require support for this project, or you would like to contact the maintainers and/or the community refer to the [support information and communication channels](SUPPORT.md).

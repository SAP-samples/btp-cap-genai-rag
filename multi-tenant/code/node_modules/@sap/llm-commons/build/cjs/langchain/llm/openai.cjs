'use strict';

var openai = require('langchain/llms/openai');
var client_openai = require('../../client/openai.cjs');
require('../../base-921f7eb6.cjs');
require('@sap-cloud-sdk/util');
require('../../index-2134ea38.cjs');
require('@sap/xsenv');
require('fs');
require('util');
require('axios');

var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class BTPOpenAIGPT extends openai.OpenAI {
  constructor(fields) {
    var _a;
    super(__spreadProps(__spreadValues({}, fields), { openAIApiKey: "dummy" }));
    __publicField(this, "btpOpenAIClient");
    __publicField(this, "deployment_id");
    this.deployment_id = (_a = fields == null ? void 0 : fields.deployment_id) != null ? _a : "text-davinci-003";
    this.btpOpenAIClient = new client_openai.BTPOpenAIGPTClient();
  }
  async _generate(prompts, options, runManager) {
    const res = await this.caller.callWithOptions(
      {
        signal: options.signal
      },
      () => {
        var _a, _b;
        return this.btpOpenAIClient.createCompletion(
          {
            prompt: prompts,
            deployment_id: this.deployment_id,
            max_tokens: this.maxTokens === -1 ? void 0 : this.maxTokens,
            temperature: this.temperature,
            top_p: this.topP,
            logit_bias: this.logitBias,
            n: this.n,
            stop: (_a = options == null ? void 0 : options.stop) != null ? _a : this.stop,
            presence_penalty: this.presencePenalty,
            frequency_penalty: this.frequencyPenalty,
            best_of: this.bestOf
          },
          {
            signal: options.signal,
            timeout: (_b = this.timeout) != null ? _b : options.timeout
          }
        );
      }
    );
    await (runManager == null ? void 0 : runManager.handleLLMNewToken(res.choices[0].text));
    return {
      generations: res.choices.map((c) => [
        {
          text: c.text,
          generationInfo: {
            finish_reason: c.finish_reason,
            index: c.index,
            logprobs: c.logprobs
          }
        }
      ]),
      llmOutput: {
        created: res.created,
        id: res.id,
        model: res.model,
        object: res.object,
        tokenUsage: {
          completionTokens: res.usage.completion_tokens,
          promptTokens: res.usage.prompt_tokens,
          totalTokens: res.usage.total_tokens
        }
      }
    };
  }
}
const BTPOpenAI = BTPOpenAIGPT;

exports.BTPOpenAI = BTPOpenAI;
exports.BTPOpenAIGPT = BTPOpenAIGPT;

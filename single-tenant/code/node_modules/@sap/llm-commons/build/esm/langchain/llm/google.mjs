import { GooglePaLM } from 'langchain/llms/googlepalm';
import { BTPGooglePaLMClient } from '../../client/google.mjs';
import '../../base-540b2ebe.mjs';
import '@sap-cloud-sdk/util';
import '../../index-924dd70f.mjs';
import '@sap/xsenv';
import 'fs';
import 'util';
import 'axios';

var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class BTPGooglePaLM extends GooglePaLM {
  constructor(fields) {
    var _a, _b;
    super(__spreadProps(__spreadValues({}, fields), { apiKey: "dummy", maxOutputTokens: 1024 }));
    __publicField(this, "btpGooglePaLMClient");
    __publicField(this, "deployment_id");
    __publicField(this, "maxOutputTokens");
    this.deployment_id = (_a = fields == null ? void 0 : fields.deployment_id) != null ? _a : "gcp-text-bison-001";
    this.maxOutputTokens = (_b = fields == null ? void 0 : fields.maxOutputTokens) != null ? _b : 1024;
    this.btpGooglePaLMClient = new BTPGooglePaLMClient();
  }
  async _generate(prompts, options, runManager) {
    const res = await this.caller.callWithOptions(
      {
        signal: options.signal
      },
      () => this.btpGooglePaLMClient.predictText(
        {
          deployment_id: this.deployment_id,
          parameters: {
            maxOutputTokens: this.maxOutputTokens === -1 ? 1024 : this.maxOutputTokens,
            temperature: this.temperature,
            topK: this.topK,
            topP: this.topP
          },
          instances: prompts.map((p) => ({
            prompt: p
          }))
        },
        {
          signal: options.signal,
          timeout: options.timeout
        }
      )
    );
    await (runManager == null ? void 0 : runManager.handleLLMNewToken(res.predictions[0].content));
    return {
      generations: res.predictions.map((c) => [
        {
          text: c.content,
          generationInfo: {
            safetyAttributes: c.safetyAttributes,
            citationMetadata: c.citationMetadata
          }
        }
      ]),
      llmOutput: {
        tokenUsage: {
          completionTokens: res.metadata.tokenMetadata.outputTokenCount.totalTokens,
          promptTokens: res.metadata.tokenMetadata.inputTokenCount.totalTokens,
          totalTokens: res.metadata.tokenMetadata.inputTokenCount.totalTokens + res.metadata.tokenMetadata.outputTokenCount.totalTokens
        }
      }
    };
  }
}

export { BTPGooglePaLM };
